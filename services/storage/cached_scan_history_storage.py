"""
Cached Scan History Storage.

Redis-cached wrapper for ScanHistoryStorage providing automatic caching
with invalidation on writes and configurable TTL.
"""

import logging
import hashlib
from typing import Dict, List, Optional, Any
from services.storage.scan_history_storage import ScanHistoryStorage
from services.storage.cached_storage import CachedStorage
from services.cache_config import get_ttl_for_cache_type
from services.cache_utils import get_cache_key_for_query

logger = logging.getLogger(__name__)


class CachedScanHistoryStorage(CachedStorage):
    """
    Cached scan history storage with Redis.
    
    Wraps ScanHistoryStorage with automatic caching:
    - Caches get() operations (1 hour TTL)
    - Caches query() results (15 minutes TTL)
    - Invalidates cache on save(), delete(), bulk operations
    """
    
    def __init__(self):
        """
        Initialize cached scan history storage.
        
        Creates underlying ScanHistoryStorage and wraps it with caching.
        """
        storage = ScanHistoryStorage()
        super().__init__(
            storage=storage,
            service_name="scan_history",
            get_ttl=get_ttl_for_cache_type("scan_history"),  # 1 hour default
            query_ttl=get_ttl_for_cache_type("query_result"),  # 15 min default
            enable_query_cache=True
        )
        logger.debug("CachedScanHistoryStorage initialized")
        
        # Cache optimization notes:
        # - TTL values are configured in services/cache_config.py
        # - Cache keys are generated by CachedStorage base class
        # - Cache invalidation happens automatically on writes/deletes
        # - For cache warming, consider pre-loading frequently accessed scans
    
    def _get_query_cache_key(self, filters: Optional[Dict[str, Any]] = None,
                             limit: Optional[int] = None,
                             offset: Optional[int] = None,
                             order_by: Optional[str] = None) -> str:
        """
        Get cache key for a query, including order_by parameter.
        
        Overrides base class to include order_by in cache key generation.
        """
        # Include order_by in the cache key by adding it to a hash
        query_hash = None
        if order_by:
            # Create a hash that includes order_by for cache key uniqueness
            hash_input = f"order_by:{order_by}"
            query_hash = hashlib.md5(hash_input.encode()).hexdigest()[:8]
        
        return get_cache_key_for_query(
            self.service_name,
            query_hash=query_hash,
            filters=filters,
            limit=limit,
            offset=offset
        )
    
    def query(self, filters: Optional[Dict[str, Any]] = None, 
              limit: Optional[int] = None, 
              offset: Optional[int] = None,
              order_by: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        Query records with optional result caching, including order_by support.
        
        Overrides base class to support order_by parameter from ScanHistoryStorage.
        
        Args:
            filters: Optional filter dictionary
            limit: Optional limit on number of results
            offset: Optional offset for pagination
            order_by: Optional ORDER BY clause (default: "timestamp DESC")
            
        Returns:
            List of record dictionaries
        """
        if not self.enable_query_cache:
            return self.storage.query(filters=filters, limit=limit, offset=offset, order_by=order_by)
        
        cache_key = self._get_query_cache_key(filters, limit, offset, order_by)
        
        # Try to get from cache
        try:
            cached = self.cache.get(cache_key)
            if cached is not None:
                logger.debug(f"Query cache hit (order_by={order_by})")
                return cached
        except Exception as e:
            logger.warning(f"Query cache get failed: {e}")
        
        # Cache miss, query storage
        logger.debug(f"Query cache miss (order_by={order_by})")
        results = self.storage.query(filters=filters, limit=limit, offset=offset, order_by=order_by)
        
        # Cache results
        try:
            self.cache.set(cache_key, results, ttl=self.query_ttl)
        except Exception as e:
            logger.warning(f"Query cache set failed: {e}")
        
        return results
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        Get statistics about scan history.
        
        Delegates to underlying ScanHistoryStorage.
        
        Returns:
            Dictionary with statistics:
            - total_scans: Total number of scans
            - most_used_agent: Most frequently used agent
            - most_used_agent_count: Count for most used agent
            - average_files_scanned: Average files scanned per scan
            - recent_scans: Number of scans in last 7 days
        """
        return self.storage.get_statistics()
    
    def get_latest_swarm_analysis(self, project_path: str) -> Optional[Dict[str, Any]]:
        """
        Get the latest Swarm Analysis scan for a given project path.
        
        Delegates to underlying ScanHistoryStorage.
        
        Args:
            project_path: Path to the project
        
        Returns:
            Dictionary with scan data including full result, or None if not found
        """
        return self.storage.get_latest_swarm_analysis(project_path)
    
    def save_metrics(self, metrics: List[Dict[str, Any]]) -> bool:
        """
        Save metrics to metrics_history table.
        
        Delegates to underlying ScanHistoryStorage and invalidates query cache
        since metrics affect statistics and queries.
        
        Args:
            metrics: List of metric dictionaries
        
        Returns:
            True if saved successfully, False otherwise
        """
        result = self.storage.save_metrics(metrics)
        
        # Invalidate query cache since metrics affect statistics
        if result:
            self._invalidate_all_queries()
        
        return result
    
    def get_metrics_history(self, filters: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """
        Retrieve metrics history with optional filters.
        
        Delegates to underlying ScanHistoryStorage.
        
        Args:
            filters: Optional filter dictionary with keys:
                - metric_name: Optional metric name filter
                - project_path: Optional project path filter
                - agent_name: Optional agent name filter
                - start_time: Optional start time filter (datetime)
                - end_time: Optional end time filter (datetime)
        
        Returns:
            List of metric dictionaries
        """
        return self.storage.get_metrics_history(filters=filters)
    
    def get_analysis_metrics(self, scan_id: int) -> List[Dict[str, Any]]:
        """
        Retrieve analysis metrics for a specific scan.
        
        Delegates to underlying ScanHistoryStorage.
        
        Args:
            scan_id: ID of the scan
        
        Returns:
            List of metric dictionaries for the scan
        """
        return self.storage.get_analysis_metrics(scan_id)

